_target_: comde.comde_modules.seq2seq.SkillCompositionTransformer

seed: ${seed}

cfg:

  inseq_dim: ${language_dim} # Input sequence = sequence of skills
  lr: 1e-5
  startend_token_path: /home/jsw7460/mnt/comde_datasets/language_embeddings/bert_mappings/tokens/bert_base_start_end_tokens
  save_suffix: ${save_suffix}
  encoder_max_len: 200
  decoder_max_len: 7
  n_example: 1

  transformer_cfg:
    input_dropout_prob: 0.1

    encoder_cfg:
      num_layers: 1
      input_dim: ${language_dim}
      num_heads: 8
      ff_dim: 256
      dropout_prob: 0.15
      use_bias: True
      max_len: ${prompt_learner.cfg.encoder_max_len}
      activation_fn: relu

    decoder_cfg:
      num_layers: 1
      input_dim: ${language_dim}
      num_heads: 4
      ff_dim: 128
      dropout_prob: 0.15
      use_bias: True
      max_len: ${prompt_learner.cfg.decoder_max_len}
      activation_fn: relu
